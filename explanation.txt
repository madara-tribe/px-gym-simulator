行動（Action）としてレーザー角度を少しずつ変えて、ターゲットに当てようとする。

1. 環境の構造

要素	内容
状態 (Observation)	サーボ角度と目標角度の差（例：+20° は右に20度外れていることを意味）
行動 (Action)	0: 左へ5度回転, 1: そのまま, 2: 右へ5度回転
報酬 (Reward)	- 相対角度が小さいほど高評価（−1～+1）
- ±3度以内であれば追加報酬（ヒット成功）
終了条件 (Done)	ターゲットを当てた or ステップ回数上限に達した

2. 環境の流れ（1エピソード）

初期状態：サーボは90度。ターゲットはランダム（例：115度）
エージェントは相対角度 (+25度) を観測
最適な行動を選び、サーボを右に回転
新しい相対角度を受け取り、再度行動を選択
最終的にターゲット ±3度以内に合わせられれば報酬+成功
行動（Action）としてレーザー角度を少しずつ変えて、ターゲットに当てようとする。

3. 環境の構造
要素	内容
状態 (Observation)	サーボ角度と目標角度の差（例：+20° は右に20度外れていることを意味）
行動 (Action)	0: 左へ5度回転, 1: そのまま, 2: 右へ5度回転
報酬 (Reward)	- 相対角度が小さいほど高評価（−1～+1）
- ±3度以内であれば追加報酬（ヒット成功）
終了条件 (Done)	ターゲットを当てた or ステップ回数上限に達した

環境の流れ（1エピソード）

初期状態：サーボは90度。ターゲットはランダム（例：115度）
エージェントは相対角度 (+25度) を観測
- servo_angle（サーボの角度）は 90度にリセット
- target_angle（目標角度）は ランダムに一度だけ生成
- 状態（= 相対角度）をエージェントに返す
- 複数のstep(action)が繰り返される
最適な行動を選び、サーボを右に回転
- 各ステップで、エージェントは一度だけアクションを選択し、サーボを±5度動かす
- 新しい状態（= 相対角度）が観測され、報酬が与えられる 
新しい相対角度を受け取り、再度行動を選択
- 以下のどちらかでエピソード終了（done = True）
- サーボが目標角度 ±3度以内に到達した（＝照準成功）or 最大ステップ数（例：50ステップ）に達した
reset()が呼ばれる（＝新しいエピソードの開始）


項目	内容
1エピソード	1つの目標角度に対し、複数ステップで接近
target_angle	エピソードの開始時に一度だけランダム生成
servo_angle	各ステップでエージェントの行動により少しずつ回転
ステップの目的	サーボを目標方向に向けて調整し続けること

Q1. 相対角度とはランダム生成された角度を表すのか？
No
相対角度とは、
　target_angle（ターゲット角度） - servo_angle（サーボの現在角度）
　で定義されます。
target_angle は環境の初期化（reset()）時に1度だけランダムに生成されます（例：50〜150度）。
つまり、「相対角度」はサーボが今どれくらい目標からズレているかを表します。
　「ランダム角度そのもの」ではなく、現在との距離を示す量です。

Q2. 各ステップごとに角度がランダム生成され、サーボが右左に動くのか？
target_angle はエピソードの最初（reset時）に1度だけランダム生成されます。
各 step() ごとにランダム角度が再生成されることはありません。
サーボは、**エージェントの出すアクション（左・そのまま・右）**に応じて動きます。

Q3. 各 step ごとにとる行動は一回だけか？
例えば、target_angle = 50°, servo_angle = 100° のとき、
1回のアクションでサーボは 95〜105 の範囲にしか動かないのか？」

yes, exactly
よって、1ステップで±5度の移動しかできません。
たとえば servo_angle = 100°, target_angle = 50° のときは、次のステップで servo_angle = 95° になります。
　目標角度まで近づくには 複数ステップが必要です。

Q4. 「カメラとレーザーはサーボモータにバンドルされていて、完全に一緒に動くか？」
判定：YES（満たしている）
servo_angle の更新がエージェントのアクションによって制御され、
servo_angle によってレーザーの照準が変わる（中心が変わる）構成になっている。
よって、レーザー＝カメラ＝サーボ一体で動いているとみなせる。

Q5. 「画像中心（ic）と物体中心（oc）の差（ズレ）に基づいて追跡しているか？」
✔ 判定：YES（この考えに基づいている）
状態（observation）は次で計算されている：
def _get_relative_angle(self):
    return float(self.target_angle - self.servo_angle)
これは oc（目標の中心） - ic（現在のサーボ中心） に相当し、
その差をエージェントが受け取ってアクションを決定している構造なので、
目的の挙動（ズレを追跡する） を満たしている。

## scripts
### render() function
def render(self, mode="human"):
        self.ax.clear()
        self.ax.set_xlim(0, 180)
        self.ax.set_ylim(0, 1)
        self.ax.set_title(f"Step {self.current_step}")
        self.ax.plot(self.servo_angle, 0.5, 'ro', label='Laser')
        self.ax.plot(self.target_angle, 0.5, 'gx', label='Target')
        self.ax.legend()
        plt.pause(0.01)

matplotlib によってリアルタイムにレーザーとターゲットを描画
赤丸（ro）：レーザー位置
緑の×印（gx）：ターゲット位置
ステップごとに自動更新（アニメーション風）

### 学習専用: train_rl.py
環境作成
PPO で強化学習
モデル保存 (ppo_laser_tracker)
TensorBoard ログ出力対応

###推論・可視化専用: test_rl.py

学習済みモデルをロード
テストエピソード実行
env.render() で動作を可視化
報酬の推移を matplotlib でプロット
